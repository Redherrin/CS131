For the replies part

$ grep replied_to ../downloaded_tweets_extend_original_nolf2.tsv > downloaded_tweets_extend_original_nolf2_REPLIED.tsv
$ grep replied_to ../downloaded_tweets_extend_nolf2.tsv > downloaded_tweets_extend_nolf2_REPLIED.tsv

$ awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_original_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $2}' > influencers.NOBOTS.txt
$ awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk '($1 >=3) {print $2}' >> influencers.NOBOTS.txt


$ mkdir influ_replies
$ for INFL in `cat influencers.NOBOTS.txt` ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/$INFL.hashtags ; done


------------------------------------
For the retweets part

$ grep type=retweeted ../downloaded_tweets_extend_nolf2.tsv | cut -f 5 | cut -d"=" -f 2 | cut -d" " -f1 | sort | uniq -c | sort -n -k 1 > rt_sort
$ awk '($1 >= 3) {print $2}' rt_sort > rt_tweetids

with these tweet ids need to look for the leader
$ cut --complement -f 5 ../downloaded_tweets_extend_original_nolf2.tsv | grep -f rt_tweetids | awk '{print $2 " " $5}' > influencers_rt.txt
$ sed -e s/"    "/\;\;/ influencers_rt.txt > influers_rt_sc.txt

$ mkdir infl_retweets
$ for file in infl_retweets/*; do cat $file | sed "s/,/\n/g" > infl_retweets_split/$file ;done

---------------------------------------------------------
For generating the tables

$ cut -f 4 ../downloaded_tweets_extend_nolf2.tsv | grep . | sed -e "s/\"//g" -e "s/,/\n/g" | sort -f | uniq -i -c | sort -n -k 1 > all_hashtags
$ sed -e s/"^ "*// all_hashtags > all_hashtags_clean


$ sh table_gen.sh infl_replies 2> /dev/null | tee replies_hashtag_freqs.tsv
$ sh table_gen.sh infl_retweets_split/infl_retweets 2> /dev/null | tee retweets_hashtag_freqs.tsv

table_gen.sh looks like:
=======================================
#!/bin/bash

all_sum=$(awk -F"\t" 'BEGIN {sum = 0} {sum = sum + $1} END {print sum}' all_hashtags)

for file in $1/*
do
	# For every cluster file we can count the hashtags at the beginning
	#
	filename=$(echo $file | sed -e s/".*\/"/"\/"/g -e s/"\/"//g -e s/".hashtags"//)
	cluster_sum=$(sort -f $file | uniq -c | sort -n -k 1 | awk -F"\t" 'BEGIN {sum = 0} {sum = sum + $1} END {print sum}')

	for hashtag in `cat $file`
	do
		# Then we can process each hashtag individually
		#
		count_H_all=$(grep -yw $hashtag all_hashtags_clean | cut -d " " -f 1)
		count_H_C=$(sort $file | uniq -c | sort -n -k 1 | sed -e s/"^ "*// | grep -w $hashtag | cut -d " " -f 1)		
		
		# Then calculate and print
		#
		freq_H_C=$(echo "scale=5; $count_H_C/$cluster_sum" | bc)
		freq_H_all=$(echo "scale=5; $count_H_all/$all_sum" | bc)
		rel_freq_H=$(echo "scale=5; $freq_H_C/$freq_H_all" | bc)
		echo "$hashtag	$filename	$rel_freq_H	$freq_H_C	$freq_H_all	$count_H_C	$cluster_sum	$count_H_all	$all_sum"
	done
done
=======================================